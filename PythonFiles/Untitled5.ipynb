{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of lines =  11\n",
      "[2, 17, 13, 15, 3, 15, 5, 17, 7, 12, 8]\n",
      "no. of words =  114\n",
      "lexical\n",
      "Analysis\n",
      "a\n",
      "Lexical\n",
      "analysis\n",
      "les\n",
      "the\n",
      "First\n",
      "phase\n",
      "of\n",
      "a\n",
      "companero\n",
      "It\n",
      "takes\n",
      "the\n",
      "modlaqled\n",
      "source\n",
      "code\n",
      "from\n",
      "language\n",
      "preprocessors\n",
      "that\n",
      "are\n",
      "written\n",
      "len\n",
      "the\n",
      "form\n",
      "of\n",
      "sentences\n",
      "The\n",
      "lexical\n",
      "analyzer\n",
      "breaks\n",
      "these\n",
      "syntaxes\n",
      "santo\n",
      "a\n",
      "series\n",
      "of\n",
      "tokens\n",
      "by\n",
      "removing\n",
      "any\n",
      "whitespace\n",
      "or\n",
      "comments\n",
      "lan\n",
      "the\n",
      "source\n",
      "code\n",
      "a\n",
      "lexical\n",
      "Analyze\n",
      "reads\n",
      "the\n",
      "source\n",
      "program\n",
      "len\n",
      "character\n",
      "by\n",
      "character\n",
      "ways\n",
      "and\n",
      "reams\n",
      "the\n",
      "token\n",
      "of\n",
      "the\n",
      "source\n",
      "program\n",
      "a\n",
      "Normally\n",
      "a\n",
      "lexical\n",
      "analyzer\n",
      "doesnt\n",
      "ream\n",
      "a\n",
      "last\n",
      "of\n",
      "tokens\n",
      "lat\n",
      "reams\n",
      "a\n",
      "token\n",
      "only\n",
      "when\n",
      "the\n",
      "parser\n",
      "asks\n",
      "a\n",
      "token\n",
      "from\n",
      "ltr\n",
      "a\n",
      "Lexical\n",
      "analyzer\n",
      "may\n",
      "also\n",
      "perform\n",
      "other\n",
      "auxlmllmaw\n",
      "operation\n",
      "like\n",
      "removing\n",
      "redundant\n",
      "whate\n",
      "space\n",
      "removing\n",
      "token\n",
      "separator\n",
      "take\n",
      "semlmcolon1\n",
      "etc\n"
     ]
    }
   ],
   "source": [
    "from ocr import perform_ocr\n",
    "\n",
    "perform_ocr(\".\\image_samples\\Capture.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
